Procedures to execute the program:

Step 1: Execute the data_preprocessing.ipynb to download, preprocessing downloaded images and generate a preprocessed data file named as SVHN_data.pickle.

Step 2: Execute the data_analysis.ipynb to extract images from SVHN_data.pickle and generate two files named SVHN_weight.ckpt, SVHN_weight.ckpt.meta separately.

Step 3: Execute the prediction_test.ipynb to read in folder named ‘prediction’’s images and read in the file SVHN_weight.ckpt generated in Step 2 then predict prediction images’ results.


Note:
prediction folder contains 17 pictures cropped by author himself from Google Street View in Manhattan, New York. All the 17 images have been resized to 32 x 32.


Environment:

Softwares used:
TensorFlow 0.11
Python 2.7
Jupyter Notebook

Libraries used:
from __future__ import print_function
import matplotlib.pyplot as plt
import numpy as np
import os
import sys
import tarfile
from IPython.display import display, Image
from scipy import ndimage
from sklearn.linear_model import LogisticRegression
from sklearn.cross_validation import train_test_split
from six.moves.urllib.request import urlretrieve
from six.moves import cPickle as pickle
import scipy.io
from six.moves import range
import tensorflow as tf
import seaborn as sns
import random
from PIL import Image

